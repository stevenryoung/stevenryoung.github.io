---
layout: page
title: CV
description: "Curriculum Vitae"
header-img: "img/about-bg-blue.jpg"
---

# Objective
Research and development of machine learning techniques for large datasets.

# Fields of Interest
Data Analytics, Deep Learning, Computer Vision, Knowledge Discovery, Text Analysis,
High Performance Computing, GPU Programming.

# Selected Publications <a size="8" color="#0000EE" href="/content/citations.bib">[Bibtex]</a>
* R. Archibald, M. Doucet, T. Johnston, **S. Young**, E. Yang, and W. Heller, “Classifying and analyzing small-angle scattering data using weighted k nearest neighbors machine learning techniques,” Journal of Applied Crystallography, 2020.
* K. Hamilton, C. Schuman, **S. Young**, R. Bennink, N. Imam, and T. Humble, “Accelerating scientific computing in the post-moore’s era,” ACM Transactions on Parallel Computing (TOPC), 2020.
* M. Parsa, C. Schuman, D. Rose, B. Kay, J. Mitchell, **S. Young**, R. Dellana, W. Severa, T. Potok, K. Roy, et al., “Hyperparameter optimization in binary communication networks for neuromorphic deployment,” arXiv preprint arXiv:2005.04171, 2020.
* A. Anderson and **S. Young**, “Self-taught waveform synthesis and analysis in theamplify-and-forward relay channel,” in 2019 IEEE Cognitive Communications for Aerospace Applications Workshop (CCAAW), IEEE, 2019.
* A. Anderson, **S. Young**, F. Reed, and J. Vann, “Deep modulation (deepmod): A self-taught phy layer for resilient digital communications,” arXiv preprint arXiv:1908.11218, 2019.
* J. Chae, C. Schuman, **S. Young**, T. Johnston, D. Rose, R. Patton, and T. Potok, “Visualization system for evolutionary neural networks for deep learning,” in 2019 IEEE International Conference on Big Data (Big Data), IEEE, 2019.
* D. Hoang, J. Hamer, G. Perdue, **S. Young**, J. Miller, and A. Ghosh, “Inferring convolutional neuralnetworks’ accuracies from their architectural characterizations,” in 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), IEEE, 2019.
* J. Johnston, **S. Young**, C. Schuman, J. Chae, D. March, R. Patton, and T. Potok, “Fine-grained exploitation of mixed precision for faster cnn training,” in 2019 IEEE/ACM Workshop on Machine Learning in High Performance Computing Environments (MLHPC), IEEE, 2019.
* R. Patton, T. Johnston, **S. Young**, C. Schuman, T. Potok, D. Rose, S. Lim, J. Chae, L. Hou, S. Abousamra, et al., “Exascale deep learning to accelerate cancer research,” in 2019 IEEE International Conference on Big Data (Big Data), IEEE, 2019.
* L. Song, F. Chen, **S. Young**, C. Schuman, G. Perdue, and T. Potok, “Deep learning for vertex reconstruction of neutrino-nucleus interaction events with combined energy and time data,” in ICASSP 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2019.
* **S. Young**, P. Devineni, M. Parsa, T. Johnston, B. Kay, R. Patton, C. Schuman, D. Rose, and T. Potok, “Evolving energy efficient convolutional neural networks,” in 2019 IEEE International Conference on Big Data (Big Data), IEEE, 2019.
* A. Anderson, **S. Young**, T. Karnowski, and J. Vann, “Deepmod: An over-the-air trainablemachine modem for resilient phy layer communications,” in MILCOM 2018 IEEE Military Communications Conference (MILCOM), IEEE, 2018.
* K. Hamilton, C. Schuman, **S. Young**, N.Imam, and T. Humble, “Neural networks and graph algorithms with next-generation processors,” in 2018 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW), IEEE, 2018.
* D. Herrmannova, **S. Young**, R. Patton, C. Stahl, N. Kleinstreuer, and M. Wolfe, “Unsupervised identification of study descriptors in toxicology research: An experimental study,” arXiv preprint arXiv:1811.01183, 2018.
* R. Patton, T. Johnston, **S. Young**, C. Schuman, D. March, T. Potok, D. Rose, S. Lim, T. Karnowski, M. Ziatdinov, et al., “167-pflops deep learning for electron microscopy:From learning physics to atomic manipulation,” in Proceedings of the International Conference forHigh Performance Computing, Networking, Storage, and Analysis, IEEE Press, 2018.
* G.Perdue, A.Ghosh, M.Wospakrik, F.Akbar, D.Andrade, M.Ascencio, L.Bellantoni, A.Bercellie, M. Betancourt, G. C. Vera, et al., “Reducing model bias in a deep learning classifier using domainadversarial neural networks in the minerva experiment,” Journal of Instrumentation, 2018.
* C. Stahl, **S. Young**, D. Herrmannova, R. Patton, J. Wells, *"DeepPDF: A deep learning approach to extracting text from PDFs,"* Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC), 2018. 
* J. Liu, F. Spedalieri, K. Yao, T. Potok, C. Schuman, **S. Young**, R. Patton, G. Rose, G. Chakma, *"Adiabatic quantum computation applied to deep learning networks,"* Entropy, 2018.
* **S. Young**, A. Maksov, M. Ziatdinov, Y. Cao, M. Burch, J. Balachandran, L. Li, S. Somnath, R. Patton, S. Kanlin, R. Vasudevan, *"Data mining for better material synthesis: The case of pulsed laser deposition of complex oxides,"* Journal of Applied Physics, 2018.
* **S. Young**, D. Rose, T. Johnston, W. Heller, T. Karnowski, T. Potok, R. Patton, G. Perdue, J. Miller, *"Evolving deep networks using HPC,"* Proceedings of the 3rd Workshop on Machine Learning in HPC Environments, 2017.
* T. Johnston, **S. Young**, D. Hughes, R. Patton, D. White, *"Optimizing convolutional neural networks for cloud detection,"* Proceedings of the 3rd Workshop on Machine Learning in HPC Environments, 2017.
* C. Schuman, T. Potok, **S. Young**, R. Patton, G. Perdue, G. Chakma, A. Wyer, G. Rose, *"Neuromorphic computing for temporal scientific data classification,"* Proceedings of the Neuromorphic Computing Symposium, 2017.
* A. Terwilliger, G. Perdue, D. Isele, R. Patton, **S. Young**, *"Vertex reconstruction of neutrino interactions using deep learning,"* Proceedings of the International Joint Conference on Neural Networks (IJCNN), May 2017.
* T. Potok, C. Schuman, **S. Young**, R. Patton, F. Spedalieri, J. Liu, K. Yao, G. Rose, G. Chakma, *"A study of complex deep learning networks on high performance, neuromorphic, and quantum computers,"* Proceedings of the Workshop on Machine Learning in High Performance Computing Environments, Supercomputing, 2016.
* S. Lim, **S. Young**, R. Patton, *"An analysis of image storage systems for scalable training of deep neural networks,"* The Seventh workshop on Big Data Benchmarks, Performance Optimization, and Emerging Hardware (in conjunction with ASPLOS'16), 2016.
* **S. Young**, D. Rose, T. Karnowski, S. Lim, R. Patton, *"Optimizing deep learning hyper-parameters through an evolutionary algorithm,"* Proceedings of the Workshop on Machine Learning in High-Performance Computing Environments, Supercomputing, 2015.
* J. Holleman, I. Arel, **S. Young**, J. Lu, *"Analog inference circuits for deep learning,"* in Biomedical Circuits and Systems Conference (BioCAS), 2015 IEEE , vol., no., pp.1-4, 22-24 Oct. 2015.
* J. Lu, **S. Young**, I. Arel, and J. Holleman, *“A 1 tops/w analog deep machine-learning engine with floating-gate storage in 0.13 μm cmos,”* IEEE Journal of Solid-State Circuits, vol. 50, no. 1, pp. 270--281, 2015.
* **S. Young**, *"Scalable Hardware Efficient Deep Spatio-Temporal Inference Networks,"* PhD thesis, The University of Tennessee, 2014.
* J. Lu, **S. Young**, I. Arel, and J. Holleman, *“A 1 tops/w analog deep machine-learning engine with floating-gate storage in 0.13 μm cmos,”* in IEEE Int. Solid-State Circuits Conf.(ISSCC) Dig. Tech. Papers, 2014.
* **S. Young**, J. Lu, J. Holleman, and I. Arel, *“On the impact of approximate computation in an analog destin architecture,”* Neural Networks and Learning Systems, IEEE Transactions on, vol. 25, no. 5, pp. 934--946, 2014.
* **S. Young**, A. Davis, A. Mishtal, and I. Arel, *“Hierarchical spatiotemporal feature extraction using recurrent online clustering,”* Pattern Recognition Letters, vol. 37, pp. 115--123, 2014.
* J. Lu, **S. Young**, I. Arel, and J. Holleman, *“An analog online clustering circuit in 130nm cmos,”* in Solid-State Circuits Conference (A-SSCC), 2013 IEEE Asian, pp. 177--180, IEEE, 2013.
* **S. Young** and I. Arel, *“Recurrent clustering for unsupervised feature extraction with application to sequence detection,”* in Machine Learning and Applications (ICMLA), 2012 11th International Conference on, vol. 2, pp. 54--55, IEEE, 2012.
* T. Karnowski, I. Arel, and **S. Young**, *“Modeling temporal dynamics with function approximation in deep spatio-temporal inference network,”* in Biologically Inspired Cognitive Architectures, International Conference on, 2011.
* **S. Young**, I. Arel, T. Karnowski, and D. Rose, *“A fast and stable incremental clustering algorithm,”* in Information Technology: New Generations (ITNG), 2010 Seventh International Conference on, pp. 204--209, IEEE, 2010.
* **S. Young**, I. Arel, and O. Arazi, *“Pi-pifo: A scalable pipelined pifo memory management architecture,”* in Telecommunications, 10th International Conference on, pp. 265--270, IEEE, 2009.

# Education

## University of Tennessee, Knoxville
Major: Computer Engineering, PhD   
Graduation Date: December, 2014  
GPA: 3.81

## University of Tennessee, Knoxville
Major: Electrical Engineering, BS   
Graduation Date: May, 2010  
GPA: 3.88

# Experience

### ORNL - Computational Data Analytics, Oak Ridge, TN (Dec. 2016 - Present)  

#### Research Scientist
- Developing methods for utlizing HPC for training deep networks for large science datasets
- Developing approaches for applying deep learning to datasets with very few labeled examples

### University of Tennessee - Bredesen Center, Knoxville, TN (Jan. 2018 - Present)

#### Joint Faculty
- Teaching course on data science, machine learning, and computing
- Providing input for the admissions process for the Data Science and Engineering program

### ORNL - Computational Data Analytics, Oak Ridge, TN (Dec. 2014 - Nov. 2016)  

#### Postdoctoral Research Associate
- Developed unsupervised machine learning techniques for analysis of cyber security data
- Developed deep learning techniques for large scale datasets

### Machine Intelligence Lab, Knoxville, TN (Nov. 2008 – Dec. 2014)  

#### Research Assistant 
- Developed deep machine learning algorithms  
- Collaborated with analog device researchers to implement deep machine learning algorithms in analog electronics  

### University of Tennessee, Knoxville, TN (Aug. 2011 – May 2013)

#### Teaching Assistant  
- Taught lab for freshman level computer science course  
- Developed new lab assignments to replace assignments previously taught using outdated software

### ORNL - Computational Data Analytics, Oak Ridge, TN (July 2009 – Aug. 2009, May 2010 – Aug. 2010, May 2011 - Aug. 2011)  

#### Intern  
- Implemented MS SharePoint text mining tool that has been commercially licensed
    - Raptor: An Enterprise Knowledge Discovery Engine (Version 2.0)
- Met with sponsors to discuss project requirements
- Became proficient in C#, Java, and MS SQL

### GE Consumer and Industrial, Louisville, KY (Jan. 2008 – May 2008)  

#### Co-op  
- Managed cost take out projects on sourced products
- Checked supplier and in house test data for conformance to product specification
- Interfaced with marketing, service, quality, and suppliers

### Honeywell Aerospace, Clearwater, FL (Jan. 2007 – May 2007)  

#### Co-op  
- Built simulations in Matlab and Simulink
- Modified process for testing a product 

# Honors
- ACM Gordon Bell Prize Finalist (June 2018)
- Oak Ridge National Laboratory
    - Technology Commercialization Award (December 2016)
    - Technology Commercialization Award (December 2014)
- University of Tennessee
    - Outstanding GTA - EECS Department (2012-2013)
    - J. Wallace & Katie Dean Graduate Fellowship (2010-2014)
    - Billy and Sylvia Moore Scholarship (2008-2010)
    - Charles and Martha Sprankle Scholarship (2006-2007)
    - Alumni Valedictorian Scholarship (2005-2007)
    - James L. Howard Scholarship (2005-2006)

# Professional Service
- Machine Learning in HPC Environments (SC Workshop)
    - Organizing Committe Chair (2017-2018)
    - Program Committee Chair (2015-2016)
- IEEE Transactions on Neural Networks and Learning Systems
    - Reviewer (2017)
- International Joint Conference on Neural Networks (IJCNN)
    - Reviewer (2015-2016)

# Professional Organizations
- ACM - Member
- Eta Kappa Nu – Beta Phi Chapter
    - Vice President (2009-2010)
    - Corresponding Secretary (2010-2012)
- IEEE – Member
- Tau Beta Pi - Member

